{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "I3NY7sfLled4"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DejiangZ/Heart-Rate-Monitoring_PPG/blob/master/assignment21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTUYbQLlYUQ-"
      },
      "source": [
        "# CS576 Assignment #2: Image Classification using Convolutional Neural Networks (CNNs)\n",
        "---\n",
        "Primary TA : Jaehoon Yoo (wogns98@kaist.ac.kr)\n",
        "\n",
        "QnA Channel: Same Slack workspace but the *assignment2* channel\n",
        "\n",
        "---\n",
        "\n",
        "## Instruction\n",
        "- In this assignment, we will classify the images in CIFAR10 dataset into 10 categories (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) using Convolutional Neural Networks.\n",
        "\n",
        "- For this, you first need to implement necessary network components (e.g. residual blocks) using nn.Module class. Then, you need to implement data pipeline. Finally, you need to implement an entire training/test pipeline.\n",
        "\n",
        "- In each part, you will be given a starter code for the implementation. Please read the attached illustrations and instructions carefully to implement the codes.\n",
        "\n",
        "- As you follow the given steps, fill in the section marked ***Px.x*** (e.g. P1.1, P1.2, etc) with the appropriate code.\n",
        "\n",
        "- **DO NOT modify any of the skeleton codes** except the area where we allow you to change. Please write your codes only in the designated area.\n",
        "\n",
        "## Submission guidelines (IMPORTANT)\n",
        "- Go to the [link](https://drive.google.com/drive/folders/1pUwcUlHh-hI9RMG-vgfTozdCeyUwhXWI?usp=drive_link), find `assignment2.ipynb` and `dataset.tar.gz`, save them into your own google drive by clicking `make a copy(사본만들기)`. Find the copies in your drive, change their name to `assignment2.ipynb` and `dataset.tar.gz`, respectively, if their names were changed to e.g. `Copy of assignment2.ipynb` or `assignment2.ipynb의 사본`. Also, keep them in a single directory.\n",
        "- <font color=\"red\"> You will get the full credit **only if** you complete the code **and** write a discussion of the results in the discussion section at the bottom of this page. </font>\n",
        "- We should be able to reproduce your results using your code. Please double-check if your code runs without error and reproduces your results. Submissions failed to run or reproduce the results will get a substantial penalty.\n",
        "\n",
        "## Deliverables\n",
        "- Download your Colab notebook and submit it in a format as : **`[StudentID].ipynb`** (e.g., `20225427.ipynb`).\n",
        "- Your assignment should be submitted through **KLMS**. <font color=\"red\"> All other submissions (e.g., via email) will not be considered as valid submissions. </font>\n",
        "\n",
        "## Due date\n",
        "- **23:59:59 April 30th (Wed).**\n",
        "- Late submission is allowed until 23:59:59 May 2nd (Fri).\n",
        "- Late submission will be applied 20% penalty.\n",
        "\n",
        "## Questions\n",
        "- Please use \"assignment2\" channel in the SLACK channel as a main communication channel. When you post questions, please make it public so that all students can share the information.\n",
        "- When you post questions, please avoid posting your own implementation (eg, posting the capture image of your own implementation.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3NY7sfLled4"
      },
      "source": [
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Prerequisite: change the runtime type to **GPU**.\n",
        "\n",
        "![test](https://docs.google.com/uc?export=download&id=1Jugrjl86L9EY1ePTjH8OVMFq7gmZsoz_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYfj23oOmOr6"
      },
      "source": [
        "---\n",
        "# Prerequisite: mount your gdrive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQdqM8z8ZM6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9984fc2-06d3-45cd-9faf-b23c09d0677e"
      },
      "source": [
        "# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W1NJ35eNLmt"
      },
      "source": [
        "---\n",
        "# Prerequisite: setup the `root` directory properly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlhMEGFUi-0c"
      },
      "source": [
        "root = '/gdrive/MyDrive/Colab Notebooks/CS576HW2'\n",
        "!tar -xzf '{root}/dataset.tar.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8ANEG5WmXzS"
      },
      "source": [
        "---\n",
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxNKZxIRYURA"
      },
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTx3YvqWYURE"
      },
      "source": [
        "-----\n",
        "\n",
        "# Network Modules\n",
        "\n",
        "In this section, you need to implement three modularized layer (or network) classes as follows:\n",
        "\n",
        "(1) plain residual block (ResBlockPlain)\n",
        "(2) residual block with bottleneck (ResBlockBottleneck)\n",
        "(3) an entire network module (MyNetwork)\n",
        "\n",
        "\n",
        "In each cell, there is a starter code as well as a schematic illustration and instruction for implementing that module class. Specifically, the schematic illustrations are to show you the computational graphs of modules, which give you high-level views on how the modules should be constructed and work. (E.g. which nn.Module to use, or input/output shape of each layer written in italics). Therefore, please read the illustrations and instructions carefully to complete the codes.\n",
        "\n",
        "Below is an example.\n",
        "\n",
        "### Example: ConvLayer Module [(Illustration)](https://docs.google.com/drawings/d/1_aPhPSPgh5-5FEfI_jnfp8r6-wNjY_QYXBT3zzjkHk0/edit?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UCo9uoyYURE"
      },
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, activation_type='relu', use_bn=False):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        \"\"\"Initialize a basic convolutional layer module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/1_aPhPSPgh5-5FEfI_jnfp8r6-wNjY_QYXBT3zzjkHk0/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link.\n",
        "            2. Initialized network components will be referred in `forward` method\n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. in_channels (int): Number of channels in the input.\n",
        "            2. out_channels (int): Number of channels produced by the convolution.\n",
        "            3. activation_type (string, optional): Type of non-linear activation function to use. (default: 'relu')\n",
        "            4. use_bn (bool, optional): Whether to use batch normalization. (default: False)\n",
        "        \"\"\"\n",
        "        ##########################\n",
        "        ## Write your code here ##\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, 3, 1, 1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
        "\n",
        "        if activation_type == 'relu':\n",
        "            self.act = nn.ReLU(True)\n",
        "        elif activation_type == 'lrelu':\n",
        "            self.act = nn.LeakyReLU(0.2, True)\n",
        "        elif activation_type == 'sigmoid':\n",
        "            self.act = nn.Sigmoid()\n",
        "        elif activation_type == 'tanh':\n",
        "            self.act = nn.Tanh()\n",
        "        elif activation_type == 'none':\n",
        "            self.act = nn.Identity()\n",
        "        else:\n",
        "            raise ValueError('Unknown activation_type !')\n",
        "        ##########################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the module.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link\n",
        "               using the initialized components in the __init__ method.\n",
        "\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): A tensor of shape (B, in_channels, H, W).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, out_channels, H, W).\n",
        "\n",
        "        \"\"\"\n",
        "        ###########################\n",
        "        ## Write your code here ##\n",
        "        output = self.conv(x)\n",
        "        output = self.bn(output)\n",
        "        output = self.act(output)\n",
        "        ###########################\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBVoTVE2YURH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ced8937-5838-4934-a455-4c3d6b16c18c"
      },
      "source": [
        "# Check and test your ConvLayer here\n",
        "# You may modify this cell for debugging\n",
        "\n",
        "in_channels = 8\n",
        "out_channels = 16\n",
        "activation_type = 'relu'\n",
        "use_bn = True\n",
        "\n",
        "convlayer_test = ConvLayer(in_channels, out_channels, activation_type, use_bn)\n",
        "print(convlayer_test)\n",
        "\n",
        "B, C, H, W = 1, in_channels, 32, 32\n",
        "x_test = torch.randn(1, C, H, W)\n",
        "print('input shape: ', x_test.shape, '| dtype: ', x_test.dtype)\n",
        "\n",
        "output = convlayer_test(x_test)\n",
        "print('output shape: ', output.shape, '| dtype: ', output.dtype)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvLayer(\n",
            "  (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (act): ReLU(inplace=True)\n",
            ")\n",
            "input shape:  torch.Size([1, 8, 32, 32]) | dtype:  torch.float32\n",
            "output shape:  torch.Size([1, 16, 32, 32]) | dtype:  torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-8Xz8c3YURK"
      },
      "source": [
        "### 1. Implement ResBlockPlain [(Illustration)](https://docs.google.com/drawings/d/1N0vi9S-RwDAjyJoC9eCVWwHnlKXfSlflf2xWTGEFRFQ/edit?usp=sharing) (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8UTAMTTYURL"
      },
      "source": [
        "class ResBlockPlain(nn.Module):\n",
        "    def __init__(self, in_channels, use_bn=False):\n",
        "        super(ResBlockPlain, self).__init__()\n",
        "        \"\"\"Initialize a residual block module components.\"\"\"\n",
        "\n",
        "        # First convolutional layer\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Batch normalization if requested\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels) if use_bn else nn.Identity()\n",
        "\n",
        "        # Activation function after first conv+bn\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Second convolutional layer\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Batch normalization if requested\n",
        "        self.bn2 = nn.BatchNorm2d(in_channels) if use_bn else nn.Identity()\n",
        "\n",
        "        # Final activation after adding the shortcut\n",
        "        self.relu_out = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the network.\"\"\"\n",
        "\n",
        "        # Store identity for the skip connection\n",
        "        identity = x\n",
        "\n",
        "        # First conv block\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # Second conv block\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        # Add skip connection\n",
        "        out += identity\n",
        "\n",
        "        # Final activation\n",
        "        out = self.relu_out(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUTlFONeYURN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd26fed-e03d-4701-f6b1-f1b0e7706a99"
      },
      "source": [
        "# Check and test your ResBlockPlain here\n",
        "# You may modify this cell for debugging\n",
        "\n",
        "in_channels = 16\n",
        "use_bn = True\n",
        "\n",
        "resblockplain_test = ResBlockPlain(in_channels, use_bn)\n",
        "print(resblockplain_test)\n",
        "\n",
        "B, C, H, W = 1, in_channels, 32, 32\n",
        "x_test = torch.randn(1, C, H, W)\n",
        "print('input shape: ', x_test.shape, '| dtype: ', x_test.dtype)\n",
        "\n",
        "output = resblockplain_test(x_test)\n",
        "print('output shape: ', output.shape, '| dtype: ', output.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResBlockPlain(\n",
            "  (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU(inplace=True)\n",
            "  (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu_out): ReLU(inplace=True)\n",
            ")\n",
            "input shape:  torch.Size([1, 16, 32, 32]) | dtype:  torch.float32\n",
            "output shape:  torch.Size([1, 16, 32, 32]) | dtype:  torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkxVx30dYURQ"
      },
      "source": [
        "### 2. Implement ResBlockBottleneck [(Illustration)](https://docs.google.com/drawings/d/1cpqMoRKtVvLy6Zwt7HziEm3DyGsbNF6jYCTCCbm5WZY/edit?usp=sharing) (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0MZNQnoYURQ"
      },
      "source": [
        "class ResBlockBottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, use_bn=False):\n",
        "        super(ResBlockBottleneck, self).__init__()\n",
        "        \"\"\"Initialize a residual block module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/1cpqMoRKtVvLy6Zwt7HziEm3DyGsbNF6jYCTCCbm5WZY/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link.\n",
        "            2. Initialized network components will be referred in `forward` method\n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. in_channels (int): Number of channels in the input.\n",
        "            2. hidden_channels (int): Number of hidden channels produced by the first ConvLayer module.\n",
        "            3. use_bn (bool, optional): Whether to use batch normalization. (default: False)\n",
        "        \"\"\"\n",
        "        #################################\n",
        "        ## P2.1. Write your code here ##\n",
        "        # First 1x1 conv to reduce dimensionality\n",
        "        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm2d(hidden_channels) if use_bn else nn.Identity()\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # 3x3 conv on reduced feature space\n",
        "        self.conv2 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(hidden_channels) if use_bn else nn.Identity()\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "        # 1x1 conv to restore dimensionality\n",
        "        self.conv3 = nn.Conv2d(hidden_channels, in_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(in_channels) if use_bn else nn.Identity()\n",
        "\n",
        "        # Final ReLU after adding the shortcut\n",
        "        self.relu_out = nn.ReLU(inplace=True)\n",
        "        #################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the network.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link\n",
        "               using the initialized components in __init__ method.\n",
        "\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): An tensor of shape (B, in_channels, H, W).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, out_channels, H, W).\n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P2.2. Write your code here ##\n",
        "        # Store identity for the skip connection\n",
        "        identity = x\n",
        "\n",
        "        # First conv block - dimensionality reduction\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # Second conv block - 3x3 convolution\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        # Third conv block - restore dimensionality\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        # Add skip connection\n",
        "        out += identity\n",
        "\n",
        "        # Final activation\n",
        "        out = self.relu_out(out)\n",
        "        ################################\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Js1eoULYURT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e882fa-b4a1-4195-ddae-1b98a3e4daa9"
      },
      "source": [
        "# Check and test your ResBlockBottleneck here\n",
        "# You may modify this cell for debugging\n",
        "\n",
        "in_channels = 16\n",
        "hidden_channels = 8\n",
        "use_bn = True\n",
        "\n",
        "resblockbottleneck_test = ResBlockBottleneck(in_channels, hidden_channels, use_bn)\n",
        "print(resblockbottleneck_test)\n",
        "\n",
        "B, C, H, W = 1, in_channels, 32, 32\n",
        "x_test = torch.randn(1, C, H, W)\n",
        "print('input shape: ', x_test.shape, '| dtype: ', x_test.dtype)\n",
        "\n",
        "output = resblockbottleneck_test(x_test)\n",
        "print('output shape: ', output.shape, '| dtype: ', output.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResBlockBottleneck(\n",
            "  (conv1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU(inplace=True)\n",
            "  (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu2): ReLU(inplace=True)\n",
            "  (conv3): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu_out): ReLU(inplace=True)\n",
            ")\n",
            "input shape:  torch.Size([1, 16, 32, 32]) | dtype:  torch.float32\n",
            "output shape:  torch.Size([1, 16, 32, 32]) | dtype:  torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXSb4yHIYURW"
      },
      "source": [
        "### 3. Implement MyNetwork [(Illustration)](https://docs.google.com/drawings/d/1dN2RLaCpK5W61A9s2WhdOfZDuDBn6JtIJmWmIAIMgtg/edit?usp=sharing) (20pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvdXrQUqYURW"
      },
      "source": [
        "class MyNetwork(nn.Module):\n",
        "    def __init__(self, nf, resblock_type='plain', num_resblocks=[1, 1, 1], use_bn=False):\n",
        "        super(MyNetwork, self).__init__()\n",
        "        \"\"\"Initialize an entire network module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/1dN2RLaCpK5W61A9s2WhdOfZDuDBn6JtIJmWmIAIMgtg/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link.\n",
        "            2. Initialized network components will be referred in `forward` method\n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. nf (int): Number of output channels for the first nn.Conv2d Module. An abbreviation for num_filter.\n",
        "            2. resblock_type (str, optional): Type of ResBlocks to use. ('plain' | 'bottleneck'. default: 'plain')\n",
        "            3. num_resblocks (list or tuple, optional): A list or tuple of length 3.\n",
        "               Each item at i-th index indicates the number of residual blocks at i-th Residual Layer.\n",
        "               (default: [1, 1, 1])\n",
        "            4. use_bn (bool, optional): Whether to use batch normalization. (default: False)\n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P3.1. Write your code here ##\n",
        "        # Initial convolution layer (input channels is always 3 for RGB images)\n",
        "        self.initial_conv = ConvLayer(3, nf, 'relu', use_bn)\n",
        "\n",
        "        # First residual layer - keep same channel dimension\n",
        "        layers1 = []\n",
        "        for _ in range(num_resblocks[0]):\n",
        "            if resblock_type == 'plain':\n",
        "                layers1.append(ResBlockPlain(nf, use_bn))\n",
        "            else:  # bottleneck\n",
        "                layers1.append(ResBlockBottleneck(nf, nf//2, use_bn))\n",
        "        self.blocks1 = nn.ModuleList(layers1)\n",
        "\n",
        "        # Downsample and double channels (nf -> 2*nf)\n",
        "        self.downsample1 = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            ConvLayer(nf, 2*nf, 'relu', use_bn)\n",
        "        )\n",
        "\n",
        "        # Second residual layer with doubled channels\n",
        "        layers2 = []\n",
        "        for _ in range(num_resblocks[1]):\n",
        "            if resblock_type == 'plain':\n",
        "                layers2.append(ResBlockPlain(2*nf, use_bn))\n",
        "            else:  # bottleneck\n",
        "                layers2.append(ResBlockBottleneck(2*nf, nf, use_bn))\n",
        "        self.blocks2 = nn.ModuleList(layers2)\n",
        "\n",
        "        # Downsample and double channels again (2*nf -> 4*nf)\n",
        "        self.downsample2 = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            ConvLayer(2*nf, 4*nf, 'relu', use_bn)\n",
        "        )\n",
        "\n",
        "        # Third residual layer with doubled channels again\n",
        "        layers3 = []\n",
        "        for _ in range(num_resblocks[2]):\n",
        "            if resblock_type == 'plain':\n",
        "                layers3.append(ResBlockPlain(4*nf, use_bn))\n",
        "            else:  # bottleneck\n",
        "                layers3.append(ResBlockBottleneck(4*nf, 2*nf, use_bn))\n",
        "        self.blocks3 = nn.ModuleList(layers3)\n",
        "\n",
        "        # Global average pooling and classifier\n",
        "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Linear(4*nf, 10)  # 10 classes for CIFAR-10\n",
        "        ################################\n",
        "\n",
        "        # When all components are initialized, perform weight initialization on weights and biases.\n",
        "        self.apply(self.init_params)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the network.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link\n",
        "               using the initialized network components in __init__ method.\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): An image tensor of shape (B, 3, 32, 32).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, 10).\n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P3.2. Write your code here ##\n",
        "        # Initial convolution\n",
        "        out = self.initial_conv(x)\n",
        "\n",
        "        # First residual layer\n",
        "        for block in self.blocks1:\n",
        "            out = block(out)\n",
        "\n",
        "        # First downsample\n",
        "        out = self.downsample1(out)\n",
        "\n",
        "        # Second residual layer\n",
        "        for block in self.blocks2:\n",
        "            out = block(out)\n",
        "\n",
        "        # Second downsample\n",
        "        out = self.downsample2(out)\n",
        "\n",
        "        # Third residual layer\n",
        "        for block in self.blocks3:\n",
        "            out = block(out)\n",
        "\n",
        "        # Global average pooling\n",
        "        out = self.global_avgpool(out)\n",
        "\n",
        "        # Flatten and classify\n",
        "        out = out.view(out.size(0), -1)\n",
        "        output = self.classifier(out)\n",
        "        ################################\n",
        "        return output\n",
        "\n",
        "    def init_params(self, m):\n",
        "        \"\"\"Perform weight initialization on model parameters.\n",
        "\n",
        "        Instructions:\n",
        "            1. For nn.Conv2d and nn.Linear modules,\n",
        "               initialize their weights using Kaiming He Normal initialization,\n",
        "               and initialize their biases with zeros.\n",
        "\n",
        "            2. For nn.BatchNorm2d modules,\n",
        "               initialize their weights with ones,\n",
        "               and initizlie their biases with zeros.\n",
        "\n",
        "            3. Otherwise, do not perform initialization.\n",
        "\n",
        "            4. No need to return anything in this method.\n",
        "\n",
        "            5. Hint: refer to the page 44 of the 'lecture note: tutorial on Pytorch [04/12]'\n",
        "\n",
        "        Args:\n",
        "            1. m (nn.Module)\n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P3.3. Write your code here ##\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "            # Kaiming He initialization for weights\n",
        "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            # Initialize weights with ones and biases with zeros\n",
        "            nn.init.ones_(m.weight)\n",
        "            nn.init.zeros_(m.bias)\n",
        "        ################################\n",
        "\n",
        "    def compute_loss(self, logit, y):\n",
        "        \"\"\"Compute cross entropy loss.\n",
        "\n",
        "        Hint:\n",
        "            If logit = torch.tensor([[-0.1, 0.2, -0.3, 0.4, -0.5, 0.6, -0.7, 0.8, -0.9, 1.0]]).float(),\n",
        "            and y = torch.ones(1).long(), then loss value equals to 2.3364xxxx\n",
        "\n",
        "        Args:\n",
        "            1. logit (torch.FloatTensor): A tensor of shape (B, 10).\n",
        "            2. y (torch.LongTensor): A tensor of shape (B).\n",
        "\n",
        "        Returns:\n",
        "            1. loss (torch.FloatTensor): Computed cross entropy loss.\n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P3.4. Write your code here ##\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        ################################\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5pkWG-NYURY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf95fd5-6b7a-41ed-c156-41f47958f69a"
      },
      "source": [
        "# Check and test your Network here\n",
        "# You may modify this cell for debugging\n",
        "\n",
        "num_filters = 16\n",
        "num_resblocks = [1, 1, 1]\n",
        "resblock_type = 'bottleneck'\n",
        "use_bn = True\n",
        "\n",
        "mynetwork_test = MyNetwork(num_filters, resblock_type, num_resblocks, use_bn)\n",
        "print(mynetwork_test)\n",
        "\n",
        "B, C, H, W = 1, 3, 32, 32\n",
        "x_test = torch.randn(1, C, H, W)\n",
        "y_test = torch.ones(1).long()\n",
        "print('input shape: ', x_test.shape, '| dtype: ', x_test.dtype)\n",
        "print('label shape: ', y_test.shape, '| dtype: ', y_test.dtype)\n",
        "\n",
        "logit = mynetwork_test(x_test)\n",
        "print('logit shape: ', logit.shape, '| dtype: ', logit.dtype)\n",
        "\n",
        "loss_test = mynetwork_test.compute_loss(logit, y_test)\n",
        "print('computed loss:', loss_test.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyNetwork(\n",
            "  (initial_conv): ConvLayer(\n",
            "    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (act): ReLU(inplace=True)\n",
            "  )\n",
            "  (blocks1): ModuleList(\n",
            "    (0): ResBlockBottleneck(\n",
            "      (conv1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu2): ReLU(inplace=True)\n",
            "      (conv3): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu_out): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (downsample1): Sequential(\n",
            "    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (1): ConvLayer(\n",
            "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (blocks2): ModuleList(\n",
            "    (0): ResBlockBottleneck(\n",
            "      (conv1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu2): ReLU(inplace=True)\n",
            "      (conv3): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu_out): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (downsample2): Sequential(\n",
            "    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (1): ConvLayer(\n",
            "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (blocks3): ModuleList(\n",
            "    (0): ResBlockBottleneck(\n",
            "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu2): ReLU(inplace=True)\n",
            "      (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu_out): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (global_avgpool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (classifier): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "input shape:  torch.Size([1, 3, 32, 32]) | dtype:  torch.float32\n",
            "label shape:  torch.Size([1]) | dtype:  torch.int64\n",
            "logit shape:  torch.Size([1, 10]) | dtype:  torch.float32\n",
            "computed loss: 0.7502263784408569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlv0qsHZYURa"
      },
      "source": [
        "---\n",
        "\n",
        "# Dataset and DataLoader\n",
        "\n",
        "In this section, you need to implement data pipeline, as illustrated in **lecture note: [4/3] Pytorch Tutorial**\n",
        "\n",
        "Like Network section, you are provided with starter codes for the data pipeline.\n",
        "\n",
        "Please refer to the instructions carefully to complete the codes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl4gTtF3aAZj"
      },
      "source": [
        "### 4-1. Implement CIFAR10 Dataset Class (15pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVl8_hECYURb"
      },
      "source": [
        "class CIFAR10(Dataset):\n",
        "    \"\"\"Customized `CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
        "\n",
        "    Read the following descriptions on the dataset directory structure carefully to implement this `CIFAR10` class.\n",
        "\n",
        "    In `dataset/cifar10` directory, you have `train` and `test` directories,\n",
        "    each of which contains CIFAR10 images for the train and test, respectively.\n",
        "\n",
        "    Also, there are 10 sub-directories (from `0` to `9`) in `train` and `test` directories,\n",
        "    where the name of each sub-directory is specified by CIFAR10 classes and\n",
        "    each sub-directory contains images for those classes.\n",
        "\n",
        "    For train data, there are 10*4,800=48,000 images in total (4,800 images for each class),\n",
        "    whereas test data consists of 10*1,200=12,000 images (1,200 images for each class).\n",
        "\n",
        "    For example,\n",
        "\n",
        "    datset\n",
        "        `-- cifar10\n",
        "            |-- train\n",
        "                |-- 0\n",
        "                    |-- 00001.png\n",
        "                    |-- ...\n",
        "                    `-- 04800.png\n",
        "                |-- ...\n",
        "                `-- 9\n",
        "                    |-- 00001.png\n",
        "                    |-- ...\n",
        "                    `-- 04800.png\n",
        "            `-- test\n",
        "                |-- 0\n",
        "                    |-- 04801.png\n",
        "                    |-- ...\n",
        "                    `-- 06000.png\n",
        "                |-- ...\n",
        "                `-- 9\n",
        "                    |-- 04801.png\n",
        "                    |-- ...\n",
        "                    `-- 06000.png\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, root, train=True, transform=None):\n",
        "        super(CIFAR10, self).__init__()\n",
        "        \"\"\"\n",
        "        Instructions:\n",
        "            1. Assume that `root` equals to `dataset/cifar10`.\n",
        "\n",
        "            2. If `train` is True, then parse all paths of train images, and keep them in the list `self.paths`.\n",
        "               E.g.) self.paths = ['dataset/cifar10/train/0/00001.png', ..., 'dataset/cifar10/train/9/4800.png']\n",
        "               Also, the length of `self.paths` list should be 48,000.\n",
        "\n",
        "            3. If `train` is False, then parse all paths of test images, and keep them in the list `self.paths`.\n",
        "               E.g.) self.paths = ['dataset/cifar10/test/0/04801.png', ..., 'dataset/cifar10/test/9/06000.png']\n",
        "               Also, the length of `self.paths` list should be 12,000.\n",
        "\n",
        "        Args:\n",
        "            root (string): Root directory of dataset where directory ``cifar10`` exists.\n",
        "            train (bool, optional): If True, creates dataset from training set, otherwise\n",
        "                creates from test set. (default: True)\n",
        "            transform (callable, optional): A function/transform that takes in an PIL image\n",
        "                and returns a transformed version. E.g, ``transforms.RandomCrop`` (default: None)\n",
        "        \"\"\"\n",
        "        self.transform = transform\n",
        "\n",
        "        ################################\n",
        "        ## P4.1. Write your code here ##\n",
        "        self.paths = []\n",
        "\n",
        "        # Determine which subset (train or test) to use\n",
        "        subset = 'train' if train else 'test'\n",
        "\n",
        "        # For each class (0-9)\n",
        "        for lei_bie in range(10):\n",
        "            # Get the folder path for this class\n",
        "            lei_path = Path(root) / subset / str(lei_bie)\n",
        "\n",
        "            # Get all image files in this folder\n",
        "            all_imgs = list(lei_path.glob('*.png'))\n",
        "\n",
        "            # Add them to our paths list\n",
        "            for img_path in all_imgs:\n",
        "                self.paths.append(str(img_path))\n",
        "        ################################\n",
        "\n",
        "        assert isinstance(self.paths, (list,)), 'Wrong type. self.paths should be list.'\n",
        "        if train is True:\n",
        "            assert len(self.paths) == 48000, 'There are 48,000 train images, but you have gathered %d image paths' % len(self.paths)\n",
        "        else:\n",
        "            assert len(self.paths) == 12000, 'There are 12,000 test images, but you have gathered %d image paths' % len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Instructions:\n",
        "            1. Given a path of an image, which is grabbed by self.paths[idx], infer the class label of the image.\n",
        "            2. Convert the inferred class label into torch.LongTensor with shape (), and keep it in `label` variable.`\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of self.paths\n",
        "\n",
        "        Returns:\n",
        "            image (torch.FloatTensor): An image tensor of shape (3, 32, 32).\n",
        "            label (torch.LongTensor): A label tensor of shape ().\n",
        "        \"\"\"\n",
        "\n",
        "        path = self.paths[idx]\n",
        "        # P4.2. Infer class label from `path`,\n",
        "        # Extract the class from the path\n",
        "        # The path has format like: 'dataset/cifar10/train/3/00123.png'\n",
        "        # So we split by '/' and take the class directory name\n",
        "        parts = path.split('/')\n",
        "        lei_bie = int(parts[-2])  # Get the class number from path\n",
        "\n",
        "        # P4.3. Convert it to torch.LongTensor with shape ().\n",
        "        label = torch.tensor(lei_bie, dtype=torch.long)\n",
        "\n",
        "        image = Image.open(path)\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZIE-uOHYURd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31c7a76-e059-4dfd-9497-504a90ca5a9c"
      },
      "source": [
        "# Check and test your CIFAR10 Dataset class here.\n",
        "# You may modify this cell for debugging\n",
        "\n",
        "data_dir = 'dataset/cifar10'\n",
        "train = True\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "dset = CIFAR10(data_dir, train, transform)\n",
        "print('num data:', len(dset))\n",
        "\n",
        "x_test, y_test = dset[0]\n",
        "print('image shape:', x_test.shape, '| type:', x_test.dtype)\n",
        "print('label shape:', y_test.shape, '| type:', y_test.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num data: 48000\n",
            "image shape: torch.Size([3, 32, 32]) | type: torch.float32\n",
            "label shape: torch.Size([]) | type: torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-F_pYcbYURg"
      },
      "source": [
        "### 4-2. Implement DataLoader (5pt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8ZmoESrYURg"
      },
      "source": [
        "def get_dataloader(args):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        ])\n",
        "    train_dataset = CIFAR10(args.dataroot, train=True, transform=transform)\n",
        "    test_dataset = CIFAR10(args.dataroot, train=False, transform=transform)\n",
        "\n",
        "    # P4.4. Use `DataLoader` module for mini-batching train and test datasets.\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "    return train_dataloader, test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_kBr92qYURi"
      },
      "source": [
        "---\n",
        "\n",
        "# 5. Train/Test Pipeline (40pt)\n",
        "\n",
        "In this section, you need to implement the entire train and test loop in the pipeline.\n",
        "\n",
        "Specifically, you need to do the followings:\n",
        "1. feed inputs into the network, get outputs, and then compute classification loss.\n",
        "2. backward the computed loss and update network weights (only in the training loop).\n",
        "3. save tensorboard logs frequently.\n",
        "4. save checkpoint weights frequently.\n",
        "\n",
        "Please refer to the **[supplementary] Pytorch Tutorial** on KLMS. There are a lot of hints for implementing this pipeline !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vcdKxr7YURj"
      },
      "source": [
        "# Configurations & Hyper-parameters\n",
        "# You may modify this cell for your experiments.\n",
        "\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "args = edict()\n",
        "\n",
        "# basic options\n",
        "args.name = 'main'                   # experiment name.\n",
        "args.resume = False                  # whether to resume. If you want to resume training, change this option.\n",
        "args.ckpt_dir = 'ckpts'              # checkpoint directory name.\n",
        "args.ckpt_reload = '10'              # If you want to resume training, specify which epoch's checkpoint to re-load.\n",
        "args.gpu = True                      # whether or not to use gpu.\n",
        "\n",
        "# network options\n",
        "args.num_filters = 32                # number of output channels in the first nn.Conv2d module in MyNetwork.\n",
        "args.resblock_type = 'bottleneck'    # type of residual block. ('plain' | 'bottleneck').\n",
        "args.num_resblocks = [1, 2, 3]       # number of residual blocks in each Residual Layer.\n",
        "args.use_bn = False                  # whether or not to use batch normalization.\n",
        "\n",
        "# data options\n",
        "args.dataroot = 'dataset/cifar10'    # where CIFAR10 images exist.\n",
        "args.batch_size = 64                 # number of mini-batch size.\n",
        "\n",
        "# training options\n",
        "args.lr = 0.0001                     # learning rate.\n",
        "args.epoch = 50                      # training epoch.\n",
        "\n",
        "# tensorboard options\n",
        "args.tensorboard = True             # whether or not to use tensorboard logging.\n",
        "args.log_dir = 'logs'                # to which tensorboard logs will be saved.\n",
        "args.log_iter = 100                  # how frequently logs are saved."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cx7EgI__gse"
      },
      "source": [
        "# Basic settings\n",
        "device = 'cuda' if torch.cuda.is_available() and args.gpu else 'cpu'\n",
        "\n",
        "result_dir = Path(root) / 'results' / args.name\n",
        "ckpt_dir = result_dir / args.ckpt_dir\n",
        "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "log_dir = result_dir / args.log_dir\n",
        "log_dir.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0Ih-Yg0YURn"
      },
      "source": [
        "# Setup tensorboard.\n",
        "if args.tensorboard:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "    writer = SummaryWriter(log_dir)\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir '/gdrive/MyDrive/{str(Path(root) / 'results').replace('/gdrive/MyDrive/', '')}'\n",
        "else:\n",
        "    writer = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-ukFLINYURx"
      },
      "source": [
        "def train(args):\n",
        "\n",
        "    # Basic settings\n",
        "    device = 'cuda' if torch.cuda.is_available() and args.gpu else 'cpu'\n",
        "\n",
        "    result_dir = Path(root) / 'results' /args.name\n",
        "    ckpt_dir = result_dir / args.ckpt_dir\n",
        "    ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "    log_dir = result_dir / args.log_dir\n",
        "    log_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Added 04/18\n",
        "    if args.tensorboard:\n",
        "        from torch.utils.tensorboard import SummaryWriter\n",
        "        writer = SummaryWriter(log_dir)\n",
        "    else:\n",
        "        writer = None\n",
        "\n",
        "    epoch = 0\n",
        "    global_step = 0\n",
        "    best_accuracy = 0.\n",
        "\n",
        "    # Define your model and optimizer\n",
        "    # Complete ResBlockPlain, ResBlockBottleneck, and MyNetwork modules to proceed further.\n",
        "    net = MyNetwork(args.num_filters, args.resblock_type, args.num_resblocks, args.use_bn).to(device)\n",
        "    optimizer = optim.Adam(net.parameters(), lr=args.lr)\n",
        "\n",
        "    # Resume the training\n",
        "    if args.resume:\n",
        "        ckpt_path = ckpt_dir / ('%s.pt' % args.ckpt_reload)\n",
        "\n",
        "        try:\n",
        "            checkpoint = torch.load(ckpt_path)\n",
        "            net.load_state_dict(checkpoint['net'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "            epoch = checkpoint['epoch'] + 1\n",
        "            best_accuracy = checkpoint['best_accuracy']\n",
        "            print(f'>> Resume training from epoch {epoch+1}')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "    # Get train/test data loaders\n",
        "    # Complete CIFAR10 dataset class and get_dataloader method to proceed further.\n",
        "    train_dataloader, test_dataloader = get_dataloader(args)\n",
        "\n",
        "    # Start training\n",
        "    # Save the starting time\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epoch, args.epoch):\n",
        "        # Here starts the train loop.\n",
        "        net.train()\n",
        "\n",
        "        # start time\n",
        "        _start_time = time.time()\n",
        "\n",
        "        for x, y in train_dataloader:\n",
        "            global_step += 1\n",
        "\n",
        "            # P5.1. Send `x` and `y` to either cpu or gpu using `device` variable.\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            # P5.2. Feed `x` into the network, get an output, and keep it in a variable called `logit`.\n",
        "            logit = net(x)\n",
        "\n",
        "            # P5.3. Compute loss using `logit` and `y`, and keep it in a variable called `loss`\n",
        "            loss = net.compute_loss(logit, y)\n",
        "            accuracy = (logit.argmax(dim=1)==y).float().mean()\n",
        "\n",
        "            # P5.4. flush out the previously computed gradient\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # P5.5. backward the computed loss.\n",
        "            loss.backward()\n",
        "\n",
        "            # P5.6. update the network weights.\n",
        "            optimizer.step()\n",
        "\n",
        "            if global_step % args.log_iter == 0 and writer is not None:\n",
        "                # P5.7. Log `loss` with a tag name 'train_loss' using `writer`. Use `global_step` as a timestamp for the log.\n",
        "                writer.add_scalar('train_loss', loss.item(), global_step)\n",
        "                # P5.8. Log `accuracy` with a tag name 'train_accuracy' using `writer`. Use `global_step` as a timestamp for the log.\n",
        "                writer.add_scalar('train_accuracy', accuracy.item(), global_step)\n",
        "\n",
        "        # print train loss, acc, time spent\n",
        "        t = time.time()-_start_time\n",
        "        print(f'Epoch {epoch}/{args.epoch} || train loss={loss:.4f} train acc={accuracy*100:.3f}% time={t:.3f} secs')\n",
        "\n",
        "        # start time for test\n",
        "        _start_time = time.time()\n",
        "\n",
        "        # Here starts the test loop.\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            test_loss = 0.\n",
        "            test_accuracy = 0.\n",
        "            test_num_data = 0.\n",
        "            for x, y in test_dataloader:\n",
        "                # P5.9. Send `x` and `y` to either cpu or gpu using `device` variable.\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                # P5.10. Feed `x` into the network, get an output, and keep it in a variable called `logit`.\n",
        "                logit = net(x)\n",
        "\n",
        "                # P5.11. Compute loss using `logit` and `y`, and keep it in a variable called `loss`\n",
        "                loss = net.compute_loss(logit, y)\n",
        "                accuracy = (logit.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "                test_loss += loss.item()*x.shape[0]\n",
        "                test_accuracy += accuracy.item()*x.shape[0]\n",
        "                test_num_data += x.shape[0]\n",
        "\n",
        "            test_loss /= test_num_data\n",
        "            test_accuracy /= test_num_data\n",
        "\n",
        "            if writer is not None:\n",
        "                # P5.12. Log `test_loss` with a tag name 'test_loss' using `writer`. Use `global_step` as a timestamp for the log.\n",
        "                writer.add_scalar('test_loss', test_loss, global_step)\n",
        "                # P5.13. Log `test_accuracy` with a tag name 'test_accuracy' using `writer`. Use `global_step` as a timestamp for the log.\n",
        "                writer.add_scalar('test_accuracy', test_accuracy, global_step)\n",
        "                writer.flush()\n",
        "\n",
        "            # P5.14. Whenever `test_accuracy` is greater than `best_accuracy`, save network weights with the filename 'best.pt' in the directory specified by `ckpt_dir`.\n",
        "            #     Here, just save the network weights (i.e, you don't need to save optimizer)\n",
        "            #     Also, don't forget to update the `best_accuracy` properly.\n",
        "            if test_accuracy > best_accuracy:\n",
        "                best_accuracy = test_accuracy\n",
        "                torch.save(net.state_dict(), ckpt_dir / 'best.pt')\n",
        "\n",
        "        # P5.15. Save the checkpoint in the directory specified by `ckpt_dir` directory.\n",
        "        #    Note that the checkpoint must include network weights, optmizer states, current epoch, best acuuracy so far.\n",
        "        #    To see how those parameters are loaded, see the above cell that loads the checkpoint and resumes the training.\n",
        "        #    Hint) Write something like, torch.save(dict(epoch=, net=, optimizer=, best_accuracy=), checkpoint_filename)\n",
        "        #    Also, use `epoch` to specify the timestamp in the checkpoint filename.\n",
        "        #    E.g) if `epoch=10`, the filename can be `10.pt`\n",
        "        torch.save({'epoch': epoch, 'net': net.state_dict(), 'optimizer': optimizer.state_dict(), 'best_accuracy': best_accuracy}, ckpt_dir / f'{epoch}.pt')\n",
        "\n",
        "        # print test loss, acc, time spent\n",
        "        t = time.time()-_start_time\n",
        "        print(f'Epoch {epoch}/{args.epoch} || test loss={loss:.4f} test acc={test_accuracy*100:.3f}% time={t:.3f} secs')\n",
        "\n",
        "    # Print final accuracy with total time spent for training\n",
        "    total_t = time.time()-start_time\n",
        "    print(f'Final best accuracy : {best_accuracy*100:.3f}% total time={total_t:.3f} secs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVcX2qpAQin9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6a4d6a-63be-46e3-8852-e887de7a5722"
      },
      "source": [
        "# Training\n",
        "train(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/50 || train loss=1.5613 train acc=37.500% time=25.294 secs\n",
            "Epoch 0/50 || test loss=1.7457 test acc=42.892% time=4.559 secs\n",
            "Epoch 1/50 || train loss=1.1368 train acc=62.500% time=22.092 secs\n",
            "Epoch 1/50 || test loss=1.6314 test acc=48.192% time=4.425 secs\n",
            "Epoch 2/50 || train loss=1.2970 train acc=51.562% time=22.665 secs\n",
            "Epoch 2/50 || test loss=1.7103 test acc=50.117% time=4.438 secs\n",
            "Epoch 3/50 || train loss=1.3440 train acc=53.125% time=23.803 secs\n",
            "Epoch 3/50 || test loss=1.7318 test acc=54.708% time=5.019 secs\n",
            "Epoch 4/50 || train loss=1.0885 train acc=64.062% time=22.884 secs\n",
            "Epoch 4/50 || test loss=1.1676 test acc=56.583% time=5.065 secs\n",
            "Epoch 5/50 || train loss=1.1463 train acc=46.875% time=23.196 secs\n",
            "Epoch 5/50 || test loss=1.2928 test acc=57.783% time=4.832 secs\n",
            "Epoch 6/50 || train loss=1.2113 train acc=64.062% time=20.880 secs\n",
            "Epoch 6/50 || test loss=1.1323 test acc=59.592% time=4.504 secs\n",
            "Epoch 7/50 || train loss=1.0453 train acc=64.062% time=20.899 secs\n",
            "Epoch 7/50 || test loss=1.1465 test acc=59.892% time=4.335 secs\n",
            "Epoch 8/50 || train loss=1.1921 train acc=57.812% time=21.399 secs\n",
            "Epoch 8/50 || test loss=1.5956 test acc=57.275% time=4.548 secs\n",
            "Epoch 9/50 || train loss=0.9789 train acc=65.625% time=22.284 secs\n",
            "Epoch 9/50 || test loss=1.2607 test acc=62.600% time=4.397 secs\n",
            "Epoch 10/50 || train loss=1.0372 train acc=64.062% time=21.555 secs\n",
            "Epoch 10/50 || test loss=0.9043 test acc=63.492% time=4.425 secs\n",
            "Epoch 11/50 || train loss=0.8015 train acc=75.000% time=23.372 secs\n",
            "Epoch 11/50 || test loss=0.8414 test acc=65.150% time=4.526 secs\n",
            "Epoch 12/50 || train loss=0.7962 train acc=67.188% time=23.055 secs\n",
            "Epoch 12/50 || test loss=0.8301 test acc=64.208% time=4.644 secs\n",
            "Epoch 13/50 || train loss=1.0808 train acc=64.062% time=23.696 secs\n",
            "Epoch 13/50 || test loss=1.1378 test acc=66.550% time=4.711 secs\n",
            "Epoch 14/50 || train loss=0.8349 train acc=68.750% time=21.769 secs\n",
            "Epoch 14/50 || test loss=0.9209 test acc=66.258% time=4.280 secs\n",
            "Epoch 15/50 || train loss=0.9526 train acc=62.500% time=21.135 secs\n",
            "Epoch 15/50 || test loss=0.8669 test acc=67.108% time=4.311 secs\n",
            "Epoch 16/50 || train loss=0.9007 train acc=70.312% time=21.148 secs\n",
            "Epoch 16/50 || test loss=0.9193 test acc=67.983% time=4.283 secs\n",
            "Epoch 17/50 || train loss=0.8141 train acc=70.312% time=21.242 secs\n",
            "Epoch 17/50 || test loss=0.9680 test acc=66.692% time=4.266 secs\n",
            "Epoch 18/50 || train loss=0.6254 train acc=78.125% time=20.941 secs\n",
            "Epoch 18/50 || test loss=0.7220 test acc=67.225% time=4.559 secs\n",
            "Epoch 19/50 || train loss=0.7304 train acc=75.000% time=20.659 secs\n",
            "Epoch 19/50 || test loss=1.1180 test acc=68.717% time=4.904 secs\n",
            "Epoch 20/50 || train loss=0.6676 train acc=75.000% time=20.802 secs\n",
            "Epoch 20/50 || test loss=0.8718 test acc=67.792% time=5.648 secs\n",
            "Epoch 21/50 || train loss=0.7477 train acc=81.250% time=23.201 secs\n",
            "Epoch 21/50 || test loss=1.1915 test acc=67.167% time=4.816 secs\n",
            "Epoch 22/50 || train loss=0.5735 train acc=90.625% time=20.457 secs\n",
            "Epoch 22/50 || test loss=1.0824 test acc=69.992% time=5.152 secs\n",
            "Epoch 23/50 || train loss=0.7431 train acc=68.750% time=20.617 secs\n",
            "Epoch 23/50 || test loss=0.7437 test acc=69.683% time=5.156 secs\n",
            "Epoch 24/50 || train loss=0.6048 train acc=76.562% time=20.844 secs\n",
            "Epoch 24/50 || test loss=1.1790 test acc=70.350% time=5.340 secs\n",
            "Epoch 25/50 || train loss=0.7385 train acc=71.875% time=22.776 secs\n",
            "Epoch 25/50 || test loss=0.9555 test acc=69.525% time=5.452 secs\n",
            "Epoch 26/50 || train loss=0.5447 train acc=81.250% time=22.178 secs\n",
            "Epoch 26/50 || test loss=0.9811 test acc=71.542% time=5.760 secs\n",
            "Epoch 27/50 || train loss=0.5255 train acc=82.812% time=22.454 secs\n",
            "Epoch 27/50 || test loss=0.7818 test acc=70.950% time=5.144 secs\n",
            "Epoch 28/50 || train loss=0.7027 train acc=76.562% time=20.749 secs\n",
            "Epoch 28/50 || test loss=1.0028 test acc=71.700% time=5.060 secs\n",
            "Epoch 29/50 || train loss=1.1327 train acc=59.375% time=20.197 secs\n",
            "Epoch 29/50 || test loss=0.9004 test acc=71.842% time=4.876 secs\n",
            "Epoch 30/50 || train loss=0.5074 train acc=84.375% time=20.507 secs\n",
            "Epoch 30/50 || test loss=0.6991 test acc=71.733% time=4.479 secs\n",
            "Epoch 31/50 || train loss=0.8917 train acc=70.312% time=20.887 secs\n",
            "Epoch 31/50 || test loss=0.7449 test acc=71.358% time=4.316 secs\n",
            "Epoch 32/50 || train loss=0.7557 train acc=68.750% time=21.068 secs\n",
            "Epoch 32/50 || test loss=0.9009 test acc=72.108% time=4.280 secs\n",
            "Epoch 33/50 || train loss=0.7470 train acc=73.438% time=20.904 secs\n",
            "Epoch 33/50 || test loss=0.7085 test acc=71.550% time=4.309 secs\n",
            "Epoch 34/50 || train loss=0.4138 train acc=81.250% time=21.088 secs\n",
            "Epoch 34/50 || test loss=0.5997 test acc=71.292% time=4.277 secs\n",
            "Epoch 35/50 || train loss=0.6356 train acc=75.000% time=21.119 secs\n",
            "Epoch 35/50 || test loss=0.1994 test acc=70.858% time=4.345 secs\n",
            "Epoch 36/50 || train loss=0.4187 train acc=89.062% time=20.624 secs\n",
            "Epoch 36/50 || test loss=0.6478 test acc=70.742% time=4.743 secs\n",
            "Epoch 37/50 || train loss=0.4167 train acc=87.500% time=20.205 secs\n",
            "Epoch 37/50 || test loss=0.6566 test acc=72.233% time=5.078 secs\n",
            "Epoch 38/50 || train loss=0.4948 train acc=79.688% time=20.182 secs\n",
            "Epoch 38/50 || test loss=0.9020 test acc=72.425% time=5.085 secs\n",
            "Epoch 39/50 || train loss=0.6501 train acc=76.562% time=20.148 secs\n",
            "Epoch 39/50 || test loss=0.4957 test acc=72.117% time=4.686 secs\n",
            "Epoch 40/50 || train loss=0.5388 train acc=84.375% time=20.735 secs\n",
            "Epoch 40/50 || test loss=0.9314 test acc=73.575% time=4.310 secs\n",
            "Epoch 41/50 || train loss=0.3539 train acc=84.375% time=21.131 secs\n",
            "Epoch 41/50 || test loss=0.9768 test acc=72.458% time=4.208 secs\n",
            "Epoch 42/50 || train loss=0.4814 train acc=84.375% time=21.190 secs\n",
            "Epoch 42/50 || test loss=0.5648 test acc=72.942% time=4.282 secs\n",
            "Epoch 43/50 || train loss=0.5886 train acc=73.438% time=21.131 secs\n",
            "Epoch 43/50 || test loss=0.8002 test acc=72.325% time=4.268 secs\n",
            "Epoch 44/50 || train loss=0.2787 train acc=92.188% time=23.624 secs\n",
            "Epoch 44/50 || test loss=0.7649 test acc=72.700% time=4.737 secs\n",
            "Epoch 45/50 || train loss=0.6022 train acc=78.125% time=24.094 secs\n",
            "Epoch 45/50 || test loss=0.4105 test acc=72.075% time=4.722 secs\n",
            "Epoch 46/50 || train loss=0.3165 train acc=85.938% time=24.223 secs\n",
            "Epoch 46/50 || test loss=0.7574 test acc=73.358% time=4.832 secs\n",
            "Epoch 47/50 || train loss=0.4054 train acc=85.938% time=24.002 secs\n",
            "Epoch 47/50 || test loss=0.4157 test acc=72.367% time=4.735 secs\n",
            "Epoch 48/50 || train loss=0.3354 train acc=85.938% time=20.949 secs\n",
            "Epoch 48/50 || test loss=0.9773 test acc=73.017% time=4.430 secs\n",
            "Epoch 49/50 || train loss=0.4074 train acc=85.938% time=21.082 secs\n",
            "Epoch 49/50 || test loss=1.1852 test acc=73.383% time=4.327 secs\n",
            "Final best accuracy : 73.575% total time=1321.119 secs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z1APMygJ8Um"
      },
      "source": [
        "---\n",
        "# 6. Discussions (50pt)\n",
        "\n",
        "Train and test at least 3 models with different configurations (for example, test with `ResBlockPlain` block instead of `ResBlockBottleneck` or you may stack more layers, etc) and hyper-parameters and discuss the results. Simply reporting the results (e.g. classification accuracy) is not considered as a discussion. You should explain which components lead to differences and analyze the reason for those differences.\n",
        "\n",
        "For the experiments, you can change the configurations and hyper-parameters by modifying the values written in the cell defining configurations and hyper-parameters. **Also, don't forget to change `args.name` before you run the new experiment!**\n",
        "\n",
        "Then, run the experiments below and leave the logs including test accuracy as a proof that you actually conducted the experiments. Based on the experimental results, write your discussions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR71pz1sSl5l"
      },
      "source": [
        "* Experiment #1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKgckqCaSmLZ"
      },
      "source": [
        "# Run your Experiment here\n",
        "# You may add cells if you want"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GhEgRmOSmWP"
      },
      "source": [
        "* Experiment #2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaP--GX2SmdG"
      },
      "source": [
        "# Run your Experiment here\n",
        "# You may add cells if you want"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW1IFBbYSmki"
      },
      "source": [
        "* Experiment #3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWab_SYcSmqi"
      },
      "source": [
        "# Run your Experiment here\n",
        "# You may add cells if you want"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-uLNbb1S2RI"
      },
      "source": [
        "* Your discussions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdmbjJ3xSvx7"
      },
      "source": [
        "Write disccusions here..."
      ]
    }
  ]
}