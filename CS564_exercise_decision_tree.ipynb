{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "nav_menu": {
      "height": "309px",
      "width": "468px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DejiangZ/Heart-Rate-Monitoring_PPG/blob/master/CS564_exercise_decision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI539NYtyb9e"
      },
      "source": [
        "# Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7TSP4H2yb9g"
      },
      "source": [
        "scikit-learn uses an optimised version of the CART algorithm; however, scikit-learn implementation does not support categorical variables for now (https://scikit-learn.org/stable/modules/tree.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rndK1EAjyb9g"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l25dSaaQyb9h"
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiiN67RYyb9l"
      },
      "source": [
        "# Training and visualizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WOyO4z9yb9l"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, 2:] # petal length and width\n",
        "y = iris.target\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
        "tree_clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBhimsxdyb9o"
      },
      "source": [
        "from graphviz import Source\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(\n",
        "        tree_clf,\n",
        "        out_file=\"iris_tree.dot\",\n",
        "        feature_names=iris.feature_names[2:],\n",
        "        class_names=iris.target_names,\n",
        "        rounded=True,\n",
        "        filled=True\n",
        "    )\n",
        "\n",
        "Source.from_file(\"iris_tree.dot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pm0n2rNyb9r"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n",
        "    x1s = np.linspace(axes[0], axes[1], 100)\n",
        "    x2s = np.linspace(axes[2], axes[3], 100)\n",
        "    x1, x2 = np.meshgrid(x1s, x2s)\n",
        "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
        "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
        "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
        "    if not iris:\n",
        "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
        "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
        "    if plot_training:\n",
        "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris-Setosa\")\n",
        "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris-Versicolor\")\n",
        "        plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris-Virginica\")\n",
        "        plt.axis(axes)\n",
        "    if iris:\n",
        "        plt.xlabel(\"Petal length\", fontsize=14)\n",
        "        plt.ylabel(\"Petal width\", fontsize=14)\n",
        "    else:\n",
        "        plt.xlabel(r\"$x_1$\", fontsize=18)\n",
        "        plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n",
        "    if legend:\n",
        "        plt.legend(loc=\"lower right\", fontsize=14)\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plot_decision_boundary(tree_clf, X, y)\n",
        "plt.plot([2.45, 2.45], [0, 3], \"k-\", linewidth=2)\n",
        "plt.plot([2.45, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
        "plt.plot([4.95, 4.95], [0, 1.75], \"k:\", linewidth=2)\n",
        "plt.plot([4.85, 4.85], [1.75, 3], \"k:\", linewidth=2)\n",
        "plt.text(1.40, 1.0, \"Depth=0\", fontsize=15)\n",
        "plt.text(3.2, 1.80, \"Depth=1\", fontsize=13)\n",
        "plt.text(4.05, 0.5, \"(Depth=2)\", fontsize=11)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3y96mR3yb9u"
      },
      "source": [
        "# Predicting classes and class probabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OfrO5aQyb9u"
      },
      "source": [
        "tree_clf.predict_proba([[5, 1.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqFqmDwSyb9x"
      },
      "source": [
        "tree_clf.predict([[5, 1.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNGRAGZnyb93"
      },
      "source": [
        "# Sensitivity to training set details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjm3qdByyb94"
      },
      "source": [
        "X[(X[:, 1]==X[:, 1][y==1].max()) & (y==1)] # widest Iris versicolor flower"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYCUhkVyyb96"
      },
      "source": [
        "not_widest_versicolor = (X[:, 1]!=1.8) | (y==2)\n",
        "X_tweaked = X[not_widest_versicolor]\n",
        "y_tweaked = y[not_widest_versicolor]\n",
        "\n",
        "tree_clf_tweaked = DecisionTreeClassifier(max_depth=2, random_state=40)\n",
        "tree_clf_tweaked.fit(X_tweaked, y_tweaked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKdIpr6tyb99"
      },
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plot_decision_boundary(tree_clf_tweaked, X_tweaked, y_tweaked, legend=False)\n",
        "plt.plot([0, 7.5], [0.8, 0.8], \"k-\", linewidth=2)\n",
        "plt.plot([0, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n",
        "plt.text(1.0, 0.9, \"Depth=0\", fontsize=15)\n",
        "plt.text(1.0, 1.80, \"Depth=1\", fontsize=13)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2G02yR-yb9_"
      },
      "source": [
        "* __max_depth__: the maximum depth\n",
        "* __min_samples_split__: the minimum number of samples a node must have before it can be split\n",
        "* __min_samples_leaf__: the minimum number of samples a leaf node must have\n",
        "* __min_weight_fraction_leaf__: the same as __min_samples_leaf__ but expressed as a fraction\n",
        "* __max_leaf_nodes__: the maximum number of leaf nodes\n",
        "* __max_features__: the maximum number of features that are evaluated for splitting at each node"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhYZr4G0yb9_"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "Xm, ym = make_moons(n_samples=100, noise=0.25, random_state=53)\n",
        "\n",
        "deep_tree_clf1 = DecisionTreeClassifier(random_state=42)\n",
        "deep_tree_clf2 = DecisionTreeClassifier(min_samples_leaf=4, random_state=42)\n",
        "deep_tree_clf1.fit(Xm, ym)\n",
        "deep_tree_clf2.fit(Xm, ym)\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.subplot(121)\n",
        "plot_decision_boundary(deep_tree_clf1, Xm, ym, axes=[-1.5, 2.5, -1, 1.5], iris=False)\n",
        "plt.title(\"No restrictions\", fontsize=16)\n",
        "plt.subplot(122)\n",
        "plot_decision_boundary(deep_tree_clf2, Xm, ym, axes=[-1.5, 2.5, -1, 1.5], iris=False)\n",
        "plt.title(\"min_samples_leaf = {}\".format(deep_tree_clf2.min_samples_leaf), fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "4_iaC4nMyb-C"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1eLpr2xyb-C"
      },
      "source": [
        "### Q1: Train and fine-tune a Decision Tree for the moons dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vuVReMgyb-D"
      },
      "source": [
        "__a__. Generate a moons dataset using `make_moons(n_samples=10000, noise=0.4)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWySwCP3yb-D"
      },
      "source": [
        "Adding `random_state=42` to make this notebook's output constant:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GaTytVvyb-D"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WoJC8b8yb-G"
      },
      "source": [
        "__b__. Split it into a training set and a test set using `train_test_split()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBJuL7WVyb-H"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmdNsaXzyb-J"
      },
      "source": [
        "__c__. Use grid search with cross-validation (with the help of the `GridSearchCV` class) to find good hyperparameter values for a `DecisionTreeClassifier`. Hint: try various values for `max_leaf_nodes`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-uc0YcPyb-K"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
        "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1, cv=3)\n",
        "\n",
        "grid_search_cv.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkUNZhRxyb-M"
      },
      "source": [
        "grid_search_cv.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JggjvI67yb-P"
      },
      "source": [
        "__d__. Train it on the full training set using these hyperparameters, and measure your model's performance on the test set. You should get roughly 85% to 87% accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RGgf_uJyb-P"
      },
      "source": [
        "By default, `GridSearchCV` trains the best model found on the whole training set (you can change this by setting `refit=False`), so we don't need to do it again. We can simply evaluate the model's accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykG7oB3Myb-Q"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = grid_search_cv.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}